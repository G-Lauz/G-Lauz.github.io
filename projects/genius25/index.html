<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GENIUS 2025 | Gabriel Lauzier </title> <meta name="author" content="Gabriel Lauzier"> <meta name="description" content="Présentation par affiche pour la soirée scientifique GENIUS 2025"> <meta name="keywords" content="Gabriel Lauzier, machine learning, AI, artificial intelligence, reinforcement learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon/favicon.ico?36d1326a1a9f840c154240c670aca702"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://g-lauz.github.io//projects/genius25/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "GENIUS 2025",
            "description": "Présentation par affiche pour la soirée scientifique GENIUS 2025",
            "published": "March 26, 2025",
            "authors": [
              
              {
                "author": "Gabriel Lauzier",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Université de Sherbrooke",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Gabriel Lauzier </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>GENIUS 2025</h1> <p>Présentation par affiche pour la soirée scientifique GENIUS 2025</p> </d-title> <d-byline></d-byline> <d-article> <h1 id="guidage-dynamique-par-champs-vectoriels-pour-le-suivi-de-trajectoire-pdf">Guidage dynamique par champs vectoriels pour le suivi de trajectoire <a href="/assets/pdf/genius25_poster.pdf" target="_blank" rel="noopener noreferrer" class="btn z-depth-0 btn-pdf">PDF</a> </h1> <div id="path_following_score" class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/zoomed_vector_field_over_trajectory_nodpi-480.webp 480w,/assets/img/zoomed_vector_field_over_trajectory_nodpi-800.webp 800w,/assets/img/zoomed_vector_field_over_trajectory_nodpi-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/zoomed_vector_field_over_trajectory_nodpi.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Vector Field Over a Trajectory" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 1)</b> Champs vectoriels générés par diffusion de bruit basé sur des démonstrations d'experts pour une tâche de suivi de trajectoire. La région en bleu représente l'état le plus probable où le véhicule devrait se diriger pour satisfaire l'objectif. </div> <h2 id="introduction">Introduction</h2> <p>La majorité des fonds marins reste inexplorée, en partie, en raison de la dépendance de l’humain pour collecter des données dans un tel environnement. En effet, les ressources humaines sont limitées, surtout pour des acquisitions de données prolongées. L’utilisation de véhicules de surface autonomes semble être efficace pour augmenter l’efficacité des acquisitions de données, mais ces derniers restent limités en raison de l’environnement maritime hautement imprévisible et non linéaire. L’apprentissage par renforcement se présente donc comme une solution prometteuse pour supporter les activités d’exploration maritime.</p> <p>L’apprentissage par renforcement pose cependant plusieurs défis comme le risque et les coûts liés à l’acquisition de données et la difficulté à définir une fonction de récompense optimale. La résolution de ces défis aboutit en des architectures complexes et difficiles à implémenter. Une approche d’apprentissage par imitation pour le guidage dynamique par champs vectoriels de véhicules de surface est donc proposée. Cette proposition consiste en la récupération d’un champ vectoriel avec un modèle génératif par diffusion de bruit dans le but de guider le véhicule vers des états plus probable observé lors de l’entraînement.</p> <p>À terme, ce projet de maîtrise vise à rendre robuste, polyvalent et à simplifier l’architecture d’un système de contrôle pour véhicules de surface autonome dans le but de faciliter les applications dans des environnements maritimes.</p> <h2 id="fondements-théoriques">Fondements théoriques</h2> <h3 id="modèles-génératifs-par-diffusion-de-bruit">Modèles génératifs par diffusion de bruit</h3> <p>Les modèles de diffusion probabiliste <d-cite key="ho_denoising_2020,sohl-dickstein_deep_2015,song_generative_2019"></d-cite> font partie d’une classe de modèle génératif derrière les récents succès de modèles comme <em>StableDiffusion</em> <d-cite key="esser_scaling_2024,podell_sdxl_2024,rombach_high-resolution_2022"></d-cite> qui permet de générer des images à partir d’une requête textuelle. Ces modèles fonctionnent en procédant au débruitage itératif d’une image originalement bruitée jusqu’à l’obtention d’une image nette.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/diffusion_processes-480.webp 480w,/assets/img/diffusion_processes-800.webp 800w,/assets/img/diffusion_processes-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/diffusion_processes.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Forward and Backward Diffusion" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 2)</b> Processus de diffusion vers l'avant et l'arrière pour un modèle génératif par diffusion de bruit. <d-cite key="song_score-based_2023"></d-cite> </div> <p>Dans le contexte de la génération d’images, chaque pixel est considéré comme une dimension de l’espace de représentation. Voici donc un exemple simplifié à seulement deux dimensions pour illustrer le concept de diffusion de bruit:</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/diffusion_process-480.webp 480w,/assets/img/diffusion_process-800.webp 800w,/assets/img/diffusion_process-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/diffusion_process.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Forward Diffusion" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/reverse_diffusion_process-480.webp 480w,/assets/img/reverse_diffusion_process-800.webp 800w,/assets/img/reverse_diffusion_process-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/reverse_diffusion_process.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Backward Diffusion" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 3)</b> Processus de diffusion et de diffusion en temps inverse sur un ensemble d'échantillons de données en deux dimensions. </div> <h3 id="apprentissage-par-imitation-et-modèles-de-diffusion">Apprentissage par imitation et modèles de diffusion</h3> <p>L’apprentissage par imitation aussi connu sous le nom d’apprentissage par la démonstration consiste à apprendre un comportement à partir d’exemples d’experts. L’avantage de cette approche est l’élimination du besoin de définir une fonction de récompense manuellement, une tâche difficile et coûteuse en temps. L’apprentissage par imitation est donc une approche prometteuse pour l’apprentissage de politiques de contrôle dans des environnements complexes.</p> <p>Une technique récemment à l’état de l’art dans ce domaine est l’approche proposée avec <em>Diffusion Policy</em> <d-cite key="chi_diffusion_2024"></d-cite>. Basée sur les modèles de diffusion de bruit, cette technique permet d’apprendre une politique de contrôle pour une tâche donnée. L’approche consiste à prédire la distribution de probabilité de l’action à prendre à partir de l’état actuel du système. Cette distribution d’action est ensuite échantillonnée pour obtenir l’action à prendre.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="https://diffusion-policy.cs.columbia.edu/videos/highlight_sauce.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Sauce Pour Task" autoplay="" controls="" loop="" muted=""></video> </figure> </div> </div> <div class="caption"> <b>Figure 2)</b> Deux bras manipulateurs utilisant l'algorithme de <i>Diffusion Policy</i> <d-cite key="chi_diffusion_2024"></d-cite> pour étendre de la sauce à pizza malgré des perturbations externes. <d-footnote><a href="https://diffusion-policy.cs.columbia.edu/" rel="external nofollow noopener" target="_blank">https://diffusion-policy.cs.columbia.edu/</a></d-footnote> </div> <p>Le problème avec cette approche réside dans le fonctionnement de l’algorithme de diffusion de bruit. La nature itérative du processus de diffusion inverse requiert plusieurs appels au réseau de neurones pour obtenir une action. C’est pour cette raison qu’il s’agit d’une méthode coûteuse en temps de calcul et peu adaptée pour des applications en temps réel comme le contrôle de véhicules autonomes.</p> <h2 id="guidage-dynamique-par-champs-vectoriels-basé-sur-une-fonction-de-score">Guidage dynamique par champs vectoriels basé sur une fonction de score</h2> <p>Ce projet de recherche propose un algorithme de guidage dynamique par champs vectoriels pour le suivi de trajectoire. La fondation de cette idée repose sur l’utilisation de la fonction de score utilisée dans les modèles de diffusion de bruit tel que formulé par Song et al. <d-cite key="song_score-based_2023"></d-cite>:</p> \[\begin{equation} \label{eq:score_function} s_\theta(x) = \nabla \log p_\theta(x) = -\nabla f_\theta(x) - \underbrace{\nabla_x \log Z}_{= 0} = -\nabla f_\theta(x). \end{equation}\] <p>Cette fonction de score est le gradient de la fonction d’énergie du modèle et indique donc la direction dans laquelle les états de l’espace de représentation sont les plus probables. L’idée est donc de récupérer cette fonction de score pour générer un champ vectoriel qui guidera le véhicule vers des états plus probables observés lors de l’entraînement.</p> <p>Ce champ vectoriel est donc généré à partir de l’environnement observé par le véhicule. Ce dernier est alors utilisé pour générer des lois de commandes qui guideront le véhicule vers des états plus probables, comme le montre la <a href="#path_following_score"><b>figure 1</b></a>, où l’espace observé est l’objectif (le point rouge) à rejoindre sur une trajectoire donnée.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/score_function-480.webp 480w,/assets/img/score_function-800.webp 800w,/assets/img/score_function-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/score_function.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Fonction de score conditionnel à la classe cyan tiré d'une distribution multimodale" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 3)</b> Fonction de score conditionnel à la classe cyan tiré d'une distribution multimodale. Les flèches indiquent la direction dans laquelle les états de la classe cyan sont les plus probables. </div> <p>À la différence de <em>Diffusion Policy</em>, l’algorithme proposé ne requiert qu’un seul appel à la fonction de score pour contrôler le véhicule. Ce qui rend l’algorithme plus rapide et adapté pour des applications en temps réel. Ceci est possible en raison du changement d’espace de représentation en contraste à celle utilisée originalement dans les travaux sur` <em>Diffusion Policy</em>. Ce dernier utilise l’espace des actions en tant que représentation alors que l’algorithme proposé utilise l’espace de l’état du système. Ainsi, <em>Diffusion Policy</em> prédit une action, alors que l’algorithme proposé prédit un vecteur de direction.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 767px)" srcset="/assets/img/path_following_architecture_vertical_layout.svg"></source> <source class="responsive-img-srcset" srcset="/assets/img/path_following_architecture_horizontal_layout.svg" sizes="95vw"></source> <img src="/assets/img/path_following_architecture_horizontal_layout.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Architecture de contrôle en boucle fermée" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 4) Architecture du système de suivi de trajectoire</b> </div> <p>Ce changement impose l’utilisation d’un autre contrôleur à plus bas niveau pour transformer le vecteur de direction en une commande pour le véhicule. L’architecture de contrôle en boucle fermée est donc composée ainsi: à son entrée, l’algorithme proposé reçoit une trajectoire en position calculée préalablement par un module de planification de trajectoire. Ensuite, l’algorithme de guidage dynamique par champs vectoriels prédit un vecteur de direction qui pointe vers l’état le plus probable. Ce vecteur est ensuite utilisé par un module régulateur linéaire quadratique (<em>Linear-Quadratic Regulator</em> - LQR) qui transforme le vecteur de direction en un vecteur de force à appliquer au système. Enfin, ce vecteur de force est transformé en une commande pour le contrôle du véhicule par un module de propulsion inverse.</p> <h2 id="conclusion">Conclusion</h2> <p>Ce travail de recherche propose une nouvelle approche en matière de suivi de trajectoire pour des véhicules de surface. Le guidage dynamique par champs vectoriels basé sur une fonction de score est un algorithme d’apprentissage par imitation basé sur les algorithmes de diffusion de bruit. L’algorithme proposé est estimé plus rapide que les algorithmes de contrôle par diffusion de bruit actuel et est donc plus adapté pour des applications en temps réel. Ceci s’explique par l’élimination de la nécessité de procéder à un échantillonnage itératif pour obtenir une action. En plus d’être plus rapide, l’algorithme proposé est plus facile à interpréter en raison des champs vectoriels qu’il est possible de produire à chaque étape de l’algorithme. Cette facilité d’interprétation est un atout pour l’application de cette technique dans le monde réel avec des véhicules autonomes.</p> <p>L’espace d’observation étudié est de faibles dimensionnalités. Elle consiste en une trajectoire dans laquelle chaque point correspond à une coordonnée en deux dimensions. Pourtant, il est estimé que cette approche pourrait être étendue à un espace d’observation plus grand comme celui d’un flux vidéo ou d’une estimation des perturbations de l’environnement. Ainsi, respectivement, il serait possible de rajouter comme fonctionnalité au système de suivi de trajectoire la détection d’obstacle et la compensation de courant ou de vent fort.</p> <p>À terme, il est anticipé que l’algorithme de guidage dynamique par champs vectoriels facilite l’intégration de systèmes autonomes pour des applications d’exploration, de recherche et sauvetage, de formation de convoi, de surveillance, d’automatisation de livraison de marchandise.</p> <h2 id="lectures-complémentaires">Lectures complémentaires</h2> <ul> <li> <a href="https://yang-song.net/blog/2021/score/" target="_blank" rel="noopener noreferrer"><b>Generative Modeling by Estimating Gradients of the Data Distribution</b></a>: l’excellent blogue de Yang Song sur les modèles génératifs qui explique en plus amples détails ces concepts.</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/posts.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Gabriel Lauzier. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>